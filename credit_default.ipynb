{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tacky726/GCI-Competition/blob/main/credit_default.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QShif6ZLCnmC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "outputId": "b3f3208e-9c84-4bf7-8fd5-6140a9024df1"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-9c7993165624>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/seaborn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmiscplot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F401,F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0maxisgrid\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F401,F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mwidgets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F401,F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcolors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mxkcd_rgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrayons\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcm\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/seaborn/widgets.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mipywidgets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minteract\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFloatSlider\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIntSlider\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minteract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipywidgets/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_version\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mversion_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__protocol_version__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__jupyter_widgets_controls_version__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__jupyter_widgets_base_version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mwidgets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtraitlets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlink\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdlink\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipywidgets/widgets/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mwidget_date\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDatePicker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mwidget_output\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mwidget_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRadioButtons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mToggleButtons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mToggleButtonsStyle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropdown\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSelect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSelectionSlider\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSelectMultiple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSelectionRangeSlider\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mwidget_selectioncontainer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAccordion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mwidget_string\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHTML\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHTMLMath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mText\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTextarea\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPassword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCombobox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# ライブラリの読み込み\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsnL75uiCnmD"
      },
      "source": [
        "必要なデータの読み込みを行います。GCIの教材フォルダの構成を想定して、読み込んでいます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7S86UJm3PcOe"
      },
      "outputs": [],
      "source": [
        "# Google Colaboratoryで作業する場合はこちらも実行してください。\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# %cd 以降にこのnotebookを置いているディレクトリを指定してください。\n",
        "%cd \"/content/drive/MyDrive\"\n",
        "import pandas as pd\n",
        "!pip install pycaret\n",
        "\n",
        "\n",
        "from pycaret.classification import setup, compare_models,  create_model\n",
        "from pycaret.regression import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1V-vWC6t85uJ"
      },
      "outputs": [],
      "source": [
        "!pip install category_encoders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXM13YCeCnmE"
      },
      "outputs": [],
      "source": [
        "\n",
        "# データの読み込み\n",
        "# INPUT_DIRにtrain.csvなどのデータを置いているディレクトリを指定してください。\n",
        "INPUT_DIR = \"./input/\"\n",
        "train = pd.read_csv(INPUT_DIR + \"train.csv\")\n",
        "test = pd.read_csv(INPUT_DIR + \"test.csv\")\n",
        "sample_sub = pd.read_csv(INPUT_DIR + \"sample_submission.csv\")\n",
        "# 省略しないように設定\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "train = train.copy()\n",
        "test = test.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6aa7P4jnpi4o"
      },
      "outputs": [],
      "source": [
        "# SK_ID_CURR列の10000ごとのグループを作成\n",
        "train['SK_ID_CURR_group'] = (train['SK_ID_CURR'] // 20000) * 20000\n",
        "\n",
        "# グループごとのTARGETの平均を計算\n",
        "target_grouped_mean = train.groupby('SK_ID_CURR_group')['TARGET'].mean()\n",
        "\n",
        "# 結果を表示\n",
        "print(target_grouped_mean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VrBz0zTAIIjn"
      },
      "outputs": [],
      "source": [
        "# データフレームの行数と列数を調べる\n",
        "num_rows, num_columns = train.shape\n",
        "\n",
        "# 結果を表示\n",
        "print(f\"Number of rows: {num_rows}\")\n",
        "print(f\"Number of columns: {num_columns}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gys6y1OOKOun"
      },
      "outputs": [],
      "source": [
        "# データフレームを真ん中で分ける\n",
        "mid_index_train = len(train) // 2\n",
        "mid_index_test = len(test) // 2\n",
        "\n",
        "# 1つ目の部分に0を、2つ目の部分に1を与える列を作成\n",
        "train['Label'] = [0] * mid_index_train + [1] * (len(train) - mid_index_train)\n",
        "test['Label'] = [0] * mid_index_test + [1] * (len(test) - mid_index_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xRuLnJLdH5Bg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "# SK_ID_CURR列の10000ごとのグループを作成\n",
        "train['SK_ID_CURR_group'] = (train['SK_ID_CURR'] // 10000) * 10000\n",
        "\n",
        "# 数値列のみを対象にしてグループごとの平均を計算\n",
        "numeric_cols = train.select_dtypes(include='number').columns\n",
        "grouped_mean_all_features = train.groupby('SK_ID_CURR_group')[numeric_cols].mean()\n",
        "\n",
        "# 各列での最大値と最小値の差を計算\n",
        "max_min_diff = grouped_mean_all_features.max() - grouped_mean_all_features.min()\n",
        "\n",
        "# 全データの平均を計算\n",
        "overall_mean = train[numeric_cols].mean()\n",
        "\n",
        "# max_min_diffをoverall_meanで割る\n",
        "ratio = max_min_diff / overall_mean\n",
        "\n",
        "# ratioが0.1以上の特徴量のみを抜き出す\n",
        "significant_features = ratio[ratio >= 0.1].index\n",
        "\n",
        "# significant_featuresに含まれる特徴量の10000ごとの平均を計算\n",
        "significant_features_grouped_mean = train.groupby('SK_ID_CURR_group')[significant_features].mean()\n",
        "\n",
        "# 結果を表示\n",
        "print(significant_features_grouped_mean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZbHJmNFGeCf"
      },
      "outputs": [],
      "source": [
        "# CNT_FAM_MEMBERS列からCNT_CHILDREN列を引いた列を追加\n",
        "train['ADULT_MEMBERS'] = train['CNT_FAM_MEMBERS'] - train['CNT_CHILDREN']\n",
        "test['ADULT_MEMBERS'] = test['CNT_FAM_MEMBERS'] - test['CNT_CHILDREN']\n",
        "\n",
        "# 複合グラフ作成\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# ヒストグラム（TARGET = 0 の場合）\n",
        "train[train['TARGET'] == 0]['ADULT_MEMBERS'].plot(kind='hist', bins=50, alpha=0.5, color='blue', label='TARGET = 0')\n",
        "\n",
        "# ヒストグラム（TARGET = 1 の場合）\n",
        "train[train['TARGET'] == 1]['ADULT_MEMBERS'].plot(kind='hist', bins=50, alpha=0.5, color='red', label='TARGET = 1')\n",
        "\n",
        "# 散布図\n",
        "plt.scatter(train['ADULT_MEMBERS'], train['TARGET'], c=train['TARGET'].apply(lambda x: 'red' if x == 1 else 'blue'), alpha=0.5)\n",
        "\n",
        "plt.xlabel('ADULT_MEMBERS')\n",
        "plt.ylabel('Count / TARGET')\n",
        "plt.title('Relationship between ADULT_MEMBERS and TARGET')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "# ADULT_MEMBERSごとのTARGET列の平均を計算\n",
        "result = train.groupby('ADULT_MEMBERS')['TARGET'].mean()\n",
        "# 結果の表示\n",
        "print(result)\n",
        "# ADULT_MEMBERS列の値を変換する関数\n",
        "def convert_adult_members(df):\n",
        "    df['ADULT_MEMBERS'] = df['ADULT_MEMBERS'].apply(lambda x: 1 if x == 2.0 else 0)\n",
        "    return df\n",
        "\n",
        "# 変換を適用\n",
        "train = convert_adult_members(train)\n",
        "test = convert_adult_members(test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rLtJGYMJLjlb"
      },
      "outputs": [],
      "source": [
        "# 新しい列を作成する関数\n",
        "def create_new_flag(df):\n",
        "    df['NEW_FLAG1'] = df.apply(lambda row: 1 if row['FLAG_WORK_PHONE'] == 0 and (row['FLAG_PHONE'] == 1 or row['FLAG_EMAIL'] == 1) else 0, axis=1)\n",
        "    return df\n",
        "\n",
        "# 新しい列を作成\n",
        "train = create_new_flag(train)\n",
        "test = create_new_flag(test)\n",
        "\n",
        "# NEW_FLAGごとのTARGETの平均を計算\n",
        "train_mean = train.groupby('NEW_FLAG1')['TARGET'].mean().reset_index()\n",
        "print(train_mean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJ1OHjj6NX4V"
      },
      "outputs": [],
      "source": [
        "# 指定された列の組み合わせごとにTARGETの平均を計算\n",
        "result = train.groupby(['LIVE_CITY_NOT_WORK_CITY', 'REG_CITY_NOT_LIVE_CITY'])['TARGET'].mean().reset_index()\n",
        "\n",
        "# 結果を表示\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Ov46mrAQXbP"
      },
      "outputs": [],
      "source": [
        "# 指定された列の組み合わせごとにTARGETの平均を計算\n",
        "result = train.groupby(['REG_CITY_NOT_WORK_CITY', 'REGION_RATING_CLIENT_W_CITY'])['TARGET'].mean().reset_index()\n",
        "\n",
        "# 結果を表示\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n--bpevCO5JP"
      },
      "outputs": [],
      "source": [
        "# 新しい列を作成\n",
        "train['new_column2'] = ((train['LIVE_CITY_NOT_WORK_CITY'] == 0) & (train['REGION_RATING_CLIENT_W_CITY'] == 1)).astype(int)\n",
        "test['new_column2'] = ((test['LIVE_CITY_NOT_WORK_CITY'] == 0) & (test['REGION_RATING_CLIENT_W_CITY'] == 1)).astype(int)\n",
        "# 新しい列を作成\n",
        "train['new_column3'] = ((train['LIVE_CITY_NOT_WORK_CITY'] == 0) & (train['REGION_RATING_CLIENT_W_CITY'] == 2)).astype(int)\n",
        "test['new_column3'] = ((test['LIVE_CITY_NOT_WORK_CITY'] == 0) & (test['REGION_RATING_CLIENT_W_CITY'] == 2)).astype(int)\n",
        "# 新しい列を作成\n",
        "train['new_column4'] = ((train['LIVE_CITY_NOT_WORK_CITY'] == 0) & (train['REGION_RATING_CLIENT_W_CITY'] == 3)).astype(int)\n",
        "test['new_column4'] = ((test['LIVE_CITY_NOT_WORK_CITY'] == 0) & (test['REGION_RATING_CLIENT_W_CITY'] == 3)).astype(int)\n",
        "# 新しい列を作成\n",
        "train['new_column5'] = ((train['LIVE_CITY_NOT_WORK_CITY'] == 1) & (train['REGION_RATING_CLIENT_W_CITY'] == 1)).astype(int)\n",
        "test['new_column5'] = ((test['LIVE_CITY_NOT_WORK_CITY'] == 1) & (test['REGION_RATING_CLIENT_W_CITY'] == 1)).astype(int)\n",
        "# 新しい列を作成\n",
        "train['new_column6'] = ((train['LIVE_CITY_NOT_WORK_CITY'] == 1) & (train['REGION_RATING_CLIENT_W_CITY'] == 2)).astype(int)\n",
        "test['new_column6'] = ((test['LIVE_CITY_NOT_WORK_CITY'] == 1) & (test['REGION_RATING_CLIENT_W_CITY'] == 2)).astype(int)\n",
        "# 新しい列を作成\n",
        "train['new_column7'] = ((train['LIVE_CITY_NOT_WORK_CITY'] == 1) & (train['REGION_RATING_CLIENT_W_CITY'] == 3)).astype(int)\n",
        "test['new_column7'] = ((test['LIVE_CITY_NOT_WORK_CITY'] == 1) & (test['REGION_RATING_CLIENT_W_CITY'] == 3)).astype(int)\n",
        "# 新しい列を作成\n",
        "train['new_column8'] = ((train['REG_CITY_NOT_WORK_CITY'] == 0) & (train['REGION_RATING_CLIENT_W_CITY'] == 1)).astype(int)\n",
        "test['new_column8'] = ((test['REG_CITY_NOT_WORK_CITY'] == 0) & (test['REGION_RATING_CLIENT_W_CITY'] == 1)).astype(int)\n",
        "# 新しい列を作成\n",
        "train['new_column9'] = ((train['REG_CITY_NOT_WORK_CITY'] == 0) & (train['REGION_RATING_CLIENT_W_CITY'] == 2)).astype(int)\n",
        "test['new_column9'] = ((test['REG_CITY_NOT_WORK_CITY'] == 0) & (test['REGION_RATING_CLIENT_W_CITY'] == 2)).astype(int)\n",
        "# 新しい列を作成\n",
        "train['new_column10'] = ((train['REG_CITY_NOT_WORK_CITY'] == 0) & (train['REGION_RATING_CLIENT_W_CITY'] == 3)).astype(int)\n",
        "test['new_column10'] = ((test['REG_CITY_NOT_WORK_CITY'] == 0) & (test['REGION_RATING_CLIENT_W_CITY'] == 3)).astype(int)\n",
        "# 新しい列を作成\n",
        "train['new_column11'] = ((train['REG_CITY_NOT_WORK_CITY'] == 1) & (train['REGION_RATING_CLIENT_W_CITY'] == 1)).astype(int)\n",
        "test['new_column11'] = ((test['REG_CITY_NOT_WORK_CITY'] == 1) & (test['REGION_RATING_CLIENT_W_CITY'] == 1)).astype(int)\n",
        "# 新しい列を作成\n",
        "train['new_column12'] = ((train['REG_CITY_NOT_WORK_CITY'] == 1) & (train['REGION_RATING_CLIENT_W_CITY'] == 2)).astype(int)\n",
        "test['new_column12'] = ((test['REG_CITY_NOT_WORK_CITY'] == 1) & (test['REGION_RATING_CLIENT_W_CITY'] == 2)).astype(int)\n",
        "# 新しい列を作成\n",
        "train['new_column13'] = ((train['REG_CITY_NOT_WORK_CITY'] == 1) & (train['REGION_RATING_CLIENT_W_CITY'] == 3)).astype(int)\n",
        "test['new_column13'] = ((test['REG_CITY_NOT_WORK_CITY'] == 1) & (test['REGION_RATING_CLIENT_W_CITY'] == 3)).astype(int)\n",
        "\n",
        "# 新しい列を作成\n",
        "train['new_column14'] = ((train['REG_CITY_NOT_WORK_CITY'] == 0) & (train['LIVE_CITY_NOT_WORK_CITY'] == 0)).astype(int)\n",
        "test['new_column14'] = ((test['REG_CITY_NOT_WORK_CITY'] == 0) & (test['LIVE_CITY_NOT_WORK_CITY'] == 0)).astype(int)\n",
        "# 新しい列を作成\n",
        "train['new_column15'] = ((train['REG_CITY_NOT_WORK_CITY'] == 0) & (train['LIVE_CITY_NOT_WORK_CITY'] == 1)).astype(int)\n",
        "test['new_column15'] = ((test['REG_CITY_NOT_WORK_CITY'] == 0) & (test['LIVE_CITY_NOT_WORK_CITY'] == 1)).astype(int)\n",
        "# 新しい列を作成\n",
        "train['new_column16'] = ((train['REG_CITY_NOT_WORK_CITY'] == 1) & (train['LIVE_CITY_NOT_WORK_CITY'] == 0)).astype(int)\n",
        "test['new_column16'] = ((test['REG_CITY_NOT_WORK_CITY'] == 1) & (test['LIVE_CITY_NOT_WORK_CITY'] == 0)).astype(int)\n",
        "# 新しい列を作成\n",
        "train['new_column17'] = ((train['REG_CITY_NOT_WORK_CITY'] == 1) & (train['LIVE_CITY_NOT_WORK_CITY'] == 1)).astype(int)\n",
        "test['new_column17'] = ((test['REG_CITY_NOT_WORK_CITY'] == 1) & (test['LIVE_CITY_NOT_WORK_CITY'] == 1)).astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NuP1zcmCnmF"
      },
      "source": [
        "## 1. データの可視化と分析"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmJzxS2nCnmG"
      },
      "outputs": [],
      "source": [
        "# trainデータの確認\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "print(f\"train shape: {train.shape}\")\n",
        "# SK_ID_CURR列の10000ごとのグループを作成\n",
        "train['SK_ID_CURR_group'] = (train['SK_ID_CURR'] // 10000) * 10000\n",
        "\n",
        "# 数値列のみを対象にしてグループごとの平均を計算\n",
        "numeric_cols = train.select_dtypes(include='number').columns\n",
        "grouped_mean_all_features = train.groupby('SK_ID_CURR_group')[numeric_cols].mean()\n",
        "# 結果を表示\n",
        "print(grouped_mean_all_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jk76xtE1W19U"
      },
      "outputs": [],
      "source": [
        "# DAYS_LAST_PHONE_CHANGE列のNaNを0に置き換え、絶対値を計算\n",
        "train['ABS_DAYS_LAST_PHONE_CHANGE'] = train['DAYS_LAST_PHONE_CHANGE'].abs().fillna(99999)\n",
        "\n",
        "# AMT_REQ_CREDIT_BUREAU_MON列に30をかけた値を計算\n",
        "train['AMT_REQ_CREDIT_BUREAU_MON_30'] = train['AMT_REQ_CREDIT_BUREAU_MON'] * 30\n",
        "\n",
        "# 絶対値+-7の範囲内にAMT_REQ_CREDIT_BUREAU_MON_30の値が入っているかどうかを判定するブール列を作成\n",
        "train['IN_RANGE'] = np.abs(train['ABS_DAYS_LAST_PHONE_CHANGE'] - train['AMT_REQ_CREDIT_BUREAU_MON_30']) <= 0\n",
        "\n",
        "# IN_RANGEがTrueの行のTARGETの平均を計算\n",
        "target_mean = train.loc[train['IN_RANGE'], 'TARGET'].mean()\n",
        "\n",
        "print(f'TARGETの平均: {target_mean}')\n",
        "\n",
        "# IN_RANGE列のTrueの数を数える\n",
        "in_range_count = train['IN_RANGE'].sum()\n",
        "\n",
        "print(f'IN_RANGE列のTrueの数: {in_range_count}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JxfOBcBKXOCt"
      },
      "outputs": [],
      "source": [
        "# trainデータフレームのTARGETの全平均を計算\n",
        "target_mean_all_actual = train['TARGET'].mean()\n",
        "\n",
        "print(f'TARGETの全平均: {target_mean_all_actual}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJaW9f_Gc1WL"
      },
      "outputs": [],
      "source": [
        "def create_match_column(df):\n",
        "    # DAYS_LAST_PHONE_CHANGE列のNaNを0に置き換え、絶対値を計算\n",
        "    df['ABS_DAYS_LAST_PHONE_CHANGE'] = df['DAYS_LAST_PHONE_CHANGE'].fillna(0).abs()\n",
        "\n",
        "    # AMT_REQ_CREDIT_BUREAU_MON列に30をかけた値を計算\n",
        "    df['AMT_REQ_CREDIT_BUREAU_MON_30'] = df['AMT_REQ_CREDIT_BUREAU_MON'] * 30\n",
        "\n",
        "    # 絶対値が一致するかどうかを判定するブール列を作成し、整数に変換\n",
        "    df['MATCH'] = (df['ABS_DAYS_LAST_PHONE_CHANGE'] == df['AMT_REQ_CREDIT_BUREAU_MON_30']).astype(int)\n",
        "    return df\n",
        "\n",
        "# trainとtestデータフレームに対して新しい列を作成\n",
        "train = create_match_column(train)\n",
        "test = create_match_column(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0j6hSZwjCnmG"
      },
      "outputs": [],
      "source": [
        "# testデータの確認\n",
        "print(f\"test shape: {test.shape}\")\n",
        "test.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E1YYVLjyeVTL"
      },
      "outputs": [],
      "source": [
        "# 指定された列を削除\n",
        "train.drop(columns=['ABS_DAYS_LAST_PHONE_CHANGE', 'AMT_REQ_CREDIT_BUREAU_MON_30'], inplace=True)\n",
        "test.drop(columns=['ABS_DAYS_LAST_PHONE_CHANGE', 'AMT_REQ_CREDIT_BUREAU_MON_30'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJsg-at-gfCi"
      },
      "outputs": [],
      "source": [
        "# 数値データのみを抽出する\n",
        "numeric_data = train.select_dtypes(include=['number'])\n",
        "# 相関行列を計算\n",
        "correlation_matrix = numeric_data.corr()\n",
        "\n",
        "# 相関行列を出力\n",
        "print(\"Correlation Matrix:\")\n",
        "print(correlation_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9924ZSTS4myr"
      },
      "outputs": [],
      "source": [
        "# AMT_INCOME_TOTALを1000単位のビンに分ける\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "# 外れ値を除外する。ここでは、1パーセンタイルと99パーセンタイルを基準に外れ値を除外します。\n",
        "q_low = train['AMT_INCOME_TOTAL'].quantile(0.01)\n",
        "q_high = train['AMT_INCOME_TOTAL'].quantile(0.99)\n",
        "train_filtered = train[(train['AMT_INCOME_TOTAL'] >= q_low) & (train['AMT_INCOME_TOTAL'] <= q_high)]\n",
        "\n",
        "# AMT_INCOME_TOTALを1000単位のビンに分ける\n",
        "bins = range(0, int(train_filtered['AMT_INCOME_TOTAL'].max()) + 10000, 10000)\n",
        "labels = [f'{i}-{i+10000}' for i in bins[:-1]]\n",
        "train_filtered['INCOME_BIN'] = pd.cut(train_filtered['AMT_INCOME_TOTAL'], bins=bins, labels=labels, right=False)\n",
        "\n",
        "# INCOME_BINごとにTARGETの平均を計算\n",
        "income_target = train_filtered.groupby('INCOME_BIN')['TARGET'].mean()\n",
        "\n",
        "# 棒グラフを作成\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "income_target.plot(kind='bar', ax=ax)\n",
        "plt.xlabel('Income Range')\n",
        "plt.ylabel('Average TARGET')\n",
        "plt.title('Average TARGET by Income Range')\n",
        "ax.xaxis.set_major_locator(MaxNLocator(nbins=15))  # x軸の目盛りを間引く\n",
        "plt.xticks(rotation=45, fontsize=10)  # フォントサイズを指定\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94gmaCHI2QMn"
      },
      "outputs": [],
      "source": [
        "count = train[train['AMT_INCOME_TOTAL'] > 2000000].shape[0]\n",
        "\n",
        "# 結果を表示\n",
        "print(\"AMT_INCOME_TOTAL列が0.2を超えている人数:\", count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QfC-x9j8DEQf"
      },
      "outputs": [],
      "source": [
        "# trainの欠損値を確認\n",
        "train.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vVYDf6bPWOt"
      },
      "outputs": [],
      "source": [
        "# 新しい列 'EXT_SOURCE_1_IS_NAN' を作成\n",
        "train['EXT_SOURCE_1_IS_NAN'] = train['EXT_SOURCE_1'].isna().astype(int)\n",
        "test['EXT_SOURCE_1_IS_NAN'] = test['EXT_SOURCE_1'].isna().astype(int)\n",
        "# 新しい列 'EXT_SOURCE_3_IS_NAN' を作成\n",
        "train['EXT_SOURCE_3_IS_NAN'] = train['EXT_SOURCE_3'].isna().astype(int)\n",
        "test['EXT_SOURCE_3_IS_NAN'] = test['EXT_SOURCE_3'].isna().astype(int)\n",
        "# 新しい列 'EXT_SOURCE_3_IS_NAN' を作成\n",
        "train['OCCUPATION_TYPE_NAN'] = train['OCCUPATION_TYPE'].isna().astype(int)\n",
        "test['OCCUPATION_TYPE_NAN'] = test['OCCUPATION_TYPE'].isna().astype(int)\n",
        "# 新しい列 'EXT_SOURCE_3_IS_NAN' を作成\n",
        "train['OWN_CAR_AGE_NAN'] = train['OWN_CAR_AGE'].isna().astype(int)\n",
        "test['OWN_CAR_AGE_NAN'] = test['OWN_CAR_AGE'].isna().astype(int)\n",
        "# 新しい列 'EXT_SOURCE_3_IS_NAN' を作成\n",
        "train['AMT_REQ_CREDIT_BUREAU_HOUR_NAN'] = train['AMT_REQ_CREDIT_BUREAU_HOUR'].isna().astype(int)\n",
        "test['AMT_REQ_CREDIT_BUREAU_HOUR_NAN'] = test['AMT_REQ_CREDIT_BUREAU_HOUR'].isna().astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoOBpNUIP6tW"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PrZon8OJDLDV"
      },
      "outputs": [],
      "source": [
        "# testの欠損値を確認\n",
        "test.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VeNWMNVXOXC9"
      },
      "outputs": [],
      "source": [
        "# EXT_SOURCE_1 列が欠損値の行を抽出\n",
        "train_missing_ext_source_1 = train[train['FLAG_OWN_REALTY'].isna()]\n",
        "\n",
        "# EXT_SOURCE_1 列が埋めてある行を抽出\n",
        "train_filled_ext_source_1 = train[~train['FLAG_OWN_REALTY'].isna()]\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# TARGET 列の分布を比較\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# EXT_SOURCE_1 が欠損値の行の TARGET 分布\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.countplot(data=train_missing_ext_source_1, x='TARGET')\n",
        "plt.title('TARGET Distribution (FLAG_OWN_REALTY  is NaN)')\n",
        "plt.xlabel('TARGET')\n",
        "plt.ylabel('Count')\n",
        "\n",
        "# EXT_SOURCE_1 が埋めてある行の TARGET 分布\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.countplot(data=train_filled_ext_source_1, x='TARGET')\n",
        "plt.title('TARGET Distribution (FLAG_OWN_REALTY is Filled)')\n",
        "plt.xlabel('TARGET')\n",
        "plt.ylabel('Count')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HlhaAvIQmvRE"
      },
      "outputs": [],
      "source": [
        "test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IV-1u-aVN5mC"
      },
      "outputs": [],
      "source": [
        "# EXT_SOURCE_1 列が欠損値の行を抽出\n",
        "train_missing_ext_source_1 = train[train['OCCUPATION_TYPE'].isna()]\n",
        "\n",
        "# EXT_SOURCE_1 列が埋めてある行を抽出\n",
        "train_filled_ext_source_1 = train[~train['OCCUPATION_TYPE'].isna()]\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# TARGET 列の分布を比較\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# EXT_SOURCE_1 が欠損値の行の TARGET 分布\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.countplot(data=train_missing_ext_source_1, x='TARGET')\n",
        "plt.title('TARGET Distribution (OCCUPATION_TYPE is NaN)')\n",
        "plt.xlabel('TARGET')\n",
        "plt.ylabel('Count')\n",
        "\n",
        "# EXT_SOURCE_1 が埋めてある行の TARGET 分布\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.countplot(data=train_filled_ext_source_1, x='TARGET')\n",
        "plt.title('TARGET Distribution (OCCUPATION_TYPE is Filled)')\n",
        "plt.xlabel('TARGET')\n",
        "plt.ylabel('Count')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WNG2yOITjJUQ"
      },
      "outputs": [],
      "source": [
        "# 数値データ以外の列を削除する\n",
        "numeric_columns = train.select_dtypes(include=['number']).columns\n",
        "numeric_data = train[numeric_columns]\n",
        "\n",
        "# 相関行列を計算\n",
        "correlation_matrix = numeric_data.corr()\n",
        "\n",
        "# 相関行列を出力\n",
        "print(\"Correlation Matrix:\")\n",
        "print(correlation_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FlRAnvmRDF1X"
      },
      "outputs": [],
      "source": [
        "# EXT_SOURCE_1 列が欠損値の行を抽出\n",
        "train_missing_ext_source_1 = train[train['EXT_SOURCE_1'].isna()]\n",
        "\n",
        "# EXT_SOURCE_1 列が埋めてある行を抽出\n",
        "train_filled_ext_source_1 = train[~train['EXT_SOURCE_1'].isna()]\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# TARGET 列の分布を比較\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# EXT_SOURCE_1 が欠損値の行の TARGET 分布\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.countplot(data=train_missing_ext_source_1, x='TARGET')\n",
        "plt.title('TARGET Distribution (EXT_SOURCE_1 is NaN)')\n",
        "plt.xlabel('TARGET')\n",
        "plt.ylabel('Count')\n",
        "\n",
        "# EXT_SOURCE_1 が埋めてある行の TARGET 分布\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.countplot(data=train_filled_ext_source_1, x='TARGET')\n",
        "plt.title('TARGET Distribution (EXT_SOURCE_1 is Filled)')\n",
        "plt.xlabel('TARGET')\n",
        "plt.ylabel('Count')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2G7mwlbLGJf"
      },
      "outputs": [],
      "source": [
        "# EXT_SOURCE_1 列が欠損値の行を抽出\n",
        "train_missing_ext_source_1 = train[train['AMT_REQ_CREDIT_BUREAU_HOUR'].isna()]\n",
        "\n",
        "# EXT_SOURCE_1 列が埋めてある行を抽出\n",
        "train_filled_ext_source_1 = train[~train['AMT_REQ_CREDIT_BUREAU_HOUR'].isna()]\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# TARGET 列の分布を比較\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# EXT_SOURCE_1 が欠損値の行の TARGET 分布\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.countplot(data=train_missing_ext_source_1, x='TARGET')\n",
        "plt.title('TARGET Distribution (AMT_REQ_CREDIT_BUREAU_HOUR is NaN)')\n",
        "plt.xlabel('TARGET')\n",
        "plt.ylabel('Count')\n",
        "\n",
        "# EXT_SOURCE_1 が埋めてある行の TARGET 分布\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.countplot(data=train_filled_ext_source_1, x='TARGET')\n",
        "plt.title('TARGET Distribution (AMT_REQ_CREDIT_BUREAU_HOUR is Filled)')\n",
        "plt.xlabel('TARGET')\n",
        "plt.ylabel('Count')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_remove = [ 4, 5, 6, 7, 22,  34, 42, 44, 47,48,49,50]\n",
        "\n",
        "# Remove the specified columns\n",
        "train.drop(train.columns[columns_to_remove], axis=1, inplace=True)\n",
        "\n",
        "# Specify the columns to be removed, adjusted by -1 (so, 1~6, 21, 24, 28, 33, 41, 43, 46)\n",
        "columns_to_remove = [3, 4, 5, 6, 21, 33, 41, 43, 46,47,48,49]\n",
        "\n",
        "\n",
        "\n",
        "# Remove the specified columns from test\n",
        "test.drop(test.columns[columns_to_remove], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "NwPJH3PaJm3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# AMT_CREDITをAMT_GOODS_PRICEで割った列を追加\n",
        "train['CREDIT_GOODS_RATIO'] = train['AMT_CREDIT'] / train['AMT_GOODS_PRICE']\n",
        "test['CREDIT_GOODS_RATIO'] = test['AMT_CREDIT'] / test['AMT_GOODS_PRICE']\n",
        "# グラフ作成\n",
        "plt.figure(figsize=(10, 6))\n",
        "colors = {0: 'blue', 1: 'red'}\n",
        "plt.scatter(train['CREDIT_GOODS_RATIO'], train['TARGET'], c=train['TARGET'].apply(lambda x: colors[x]), alpha=0.5)\n",
        "plt.xlabel('CREDIT_GOODS_RATIO')\n",
        "plt.ylabel('TARGET')\n",
        "plt.title('Relationship between CREDIT_GOODS_RATIO and TARGET')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# CREDIT_GOODS_RATIO列に条件に基づいて値を設定\n",
        "train['CREDIT_GOODS_RATIO'] = train['CREDIT_GOODS_RATIO'].apply(lambda x: 0 if x <= 1 else 1)\n",
        "test['CREDIT_GOODS_RATIO'] = test['CREDIT_GOODS_RATIO'].apply(lambda x: 0 if x <= 1 else 1)\n",
        "\n",
        "# AMT_CREDITをAMT_ANNUITYで割った列を追加\n",
        "train['CREDIT_ANNUITY_RATIO'] = train['AMT_CREDIT'] / train['AMT_ANNUITY']\n",
        "test['CREDIT_ANNUITY_RATIO'] = test['AMT_CREDIT'] / test['AMT_ANNUITY']\n",
        "\n",
        "\n",
        "# 複合グラフ作成\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# ヒストグラム（TARGET = 0 の場合）\n",
        "train[train['TARGET'] == 0]['CREDIT_ANNUITY_RATIO'].plot(kind='hist', bins=50, alpha=0.5, color='blue', label='TARGET = 0')\n",
        "\n",
        "# ヒストグラム（TARGET = 1 の場合）\n",
        "train[train['TARGET'] == 1]['CREDIT_ANNUITY_RATIO'].plot(kind='hist', bins=50, alpha=0.5, color='red', label='TARGET = 1')\n",
        "\n",
        "# 散布図\n",
        "plt.scatter(train['CREDIT_ANNUITY_RATIO'], train['TARGET'], c=train['TARGET'].apply(lambda x: 'red' if x == 1 else 'blue'), alpha=0.5)\n",
        "\n",
        "plt.xlabel('CREDIT_ANNUITY_RATIO')\n",
        "plt.ylabel('Count / TARGET')\n",
        "plt.title('Relationship between CREDIT_ANNUITY_RATIO and TARGET')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# NaN の数を数える\n",
        "nan_count_train = train['CREDIT_ANNUITY_RATIO'].isna().sum()\n",
        "nan_count_test = test['CREDIT_ANNUITY_RATIO'].isna().sum()\n",
        "\n",
        "# 無限大の数を数える\n",
        "inf_count_train = np.isinf(train['CREDIT_ANNUITY_RATIO']).sum()\n",
        "inf_count_test = np.isinf(test['CREDIT_ANNUITY_RATIO']).sum()\n",
        "\n",
        "# 結果を表示\n",
        "print(f\"Train DataFrame - NaN count: {nan_count_train}, Inf count: {inf_count_train}\")\n",
        "print(f\"Test DataFrame - NaN count: {nan_count_test}, Inf count: {inf_count_test}\")\n",
        "\n",
        "# 無限大の値を NaN に置き換える\n",
        "train['CREDIT_ANNUITY_RATIO'].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "test['CREDIT_ANNUITY_RATIO'].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "# NaN の値を 0 に置き換える\n",
        "train['CREDIT_ANNUITY_RATIO'].fillna(0, inplace=True)\n",
        "test['CREDIT_ANNUITY_RATIO'].fillna(0, inplace=True)\n",
        "# CREDIT_ANNUITY_RATIOの整数部分を計算して新しい列に追加\n",
        "train['CREDIT_ANNUITY_RATIO_INT'] = train['CREDIT_ANNUITY_RATIO'].astype(int)\n",
        "\n",
        "# CREDIT_ANNUITY_RATIOの整数値ごとのTARGETの平均を計算\n",
        "ratio_target_mean = train.groupby('CREDIT_ANNUITY_RATIO_INT')['TARGET'].mean()\n",
        "# 結果を表示\n",
        "print(ratio_target_mean)\n",
        "# 列の削除\n",
        "train.drop(columns=['CREDIT_ANNUITY_RATIO_INT'], inplace=True)\n",
        "\n",
        "# CREDIT_ANNUITY_RATIO_INT列が11以上21以下のときに1、そうでないときに0を設定\n",
        "train['CREDIT_ANNUITY_RATIO'] = train['CREDIT_ANNUITY_RATIO'].apply(lambda x: 1 if 11 <= x <= 21 else 0)\n",
        "test['CREDIT_ANNUITY_RATIO'] = test['CREDIT_ANNUITY_RATIO'].apply(lambda x: 1 if 11 <= x <= 21 else 0)\n"
      ],
      "metadata": {
        "id": "zJJLh1B0JxiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import category_encoders as ce\n",
        "\n",
        "list_cols = ['NAME_INCOME_TYPE','NAME_FAMILY_STATUS','REGION_RATING_CLIENT','REGION_RATING_CLIENT_W_CITY','CODE_GENDER','NAME_CONTRACT_TYPE','DEF_30_CNT_SOCIAL_CIRCLE','DEF_60_CNT_SOCIAL_CIRCLE',]\n",
        "\n",
        "# OneHotEncodeしたい列を指定。Nullや不明の場合の補完方法も指定。\n",
        "ce_ohe = ce.OneHotEncoder(cols=list_cols,handle_unknown='impute')\n",
        "\n",
        "# pd.DataFrameをそのまま突っ込む\n",
        "train = ce_ohe.fit_transform(train)\n",
        "test = ce_ohe.fit_transform(test)\n",
        "\n",
        "# 対象の住宅タイプのリスト\n",
        "target_housing_types = ['With parents', 'Rented apartment']\n",
        "\n",
        "# 新しい列の作成\n",
        "train['HOUSING_FLAG'] = train['NAME_HOUSING_TYPE'].apply(lambda x: 1 if x in target_housing_types else 0)\n",
        "test['HOUSING_FLAG'] = test['NAME_HOUSING_TYPE'].apply(lambda x: 1 if x in target_housing_types else 0)\n",
        "\n",
        "# trainデータでNAME_EDUCATION_TYPEごとのTARGETの平均を計算\n",
        "education_target_mean = train.groupby('NAME_EDUCATION_TYPE')['TARGET'].mean().reset_index()\n",
        "education_target_mean.columns = ['NAME_EDUCATION_TYPE', 'EDUCATION_TARGET_MEAN']\n",
        "\n",
        "# trainデータに新しい列を追加\n",
        "train = pd.merge(train, education_target_mean, on='NAME_EDUCATION_TYPE', how='left')\n",
        "\n",
        "# testデータに新しい列を追加\n",
        "test = pd.merge(test, education_target_mean, on='NAME_EDUCATION_TYPE', how='left')\n",
        "\n",
        "# trainデータでORGANIZATION_TYPEごとのTARGETの平均を計算\n",
        "organization_target_mean = train.groupby('ORGANIZATION_TYPE')['TARGET'].mean().reset_index()\n",
        "organization_target_mean.columns = ['ORGANIZATION_TYPE', 'ORGANIZATION_TARGET_MEAN']\n",
        "\n",
        "# trainデータに新しい列を追加\n",
        "train = pd.merge(train, organization_target_mean, on='ORGANIZATION_TYPE', how='left')\n",
        "\n",
        "# testデータに新しい列を追加\n",
        "test = pd.merge(test, organization_target_mean, on='ORGANIZATION_TYPE', how='left')\n",
        "\n",
        "# trainデータでOCCUPATION_TYPEごとのTARGETの平均を計算\n",
        "occupation_target_mean = train.groupby('OCCUPATION_TYPE')['TARGET'].mean().reset_index()\n",
        "occupation_target_mean.columns = ['OCCUPATION_TYPE', 'OCCUPATION_TARGET_MEAN']\n",
        "\n",
        "# trainデータに新しい列を追加\n",
        "train = pd.merge(train, occupation_target_mean, on='OCCUPATION_TYPE', how='left')\n",
        "\n",
        "# testデータに新しい列を追加\n",
        "test = pd.merge(test, occupation_target_mean, on='OCCUPATION_TYPE', how='left')\n",
        "# 削除したい列名を指定\n",
        "columns_to_drop = ['ORGANIZATION_TYPE','OCCUPATION_TYPE','NAME_HOUSING_TYPE','NAME_EDUCATION_TYPE','NAME_TYPE_SUITE']\n",
        "# 指定の列を削除\n",
        "train = train.drop(columns=columns_to_drop)\n",
        "test = test.drop(columns=columns_to_drop)\n",
        "# TARGET列を除いたtrainデータの特徴量部分を抽出\n",
        "train_features = train.drop(columns=['TARGET'])\n",
        "\n",
        "# trainの列名とtestの列名を取得\n",
        "train_columns = train_features.columns\n",
        "test_columns = test.columns\n",
        "\n",
        "# trainにあってtestにない列を見つける\n",
        "missing_columns = set(train_columns) - set(test_columns)\n",
        "\n",
        "# testデータに欠けている列を追加し、すべての値を0に設定\n",
        "for column in missing_columns:\n",
        "    test[column] = 0\n",
        "\n",
        "# 列の順序をtrainデータと同じにする\n",
        "test = test[train_columns]\n",
        "\n",
        "# 0と1の比率が90%以上の列を見つけるための閾値\n",
        "threshold = 0.95\n",
        "\n",
        "# 偏りのある列を探す関数\n",
        "def find_biased_columns(df, threshold):\n",
        "    biased_columns = []\n",
        "    for column in df.columns:\n",
        "        counts = df[column].value_counts(normalize=True)\n",
        "        if (0 in counts and counts[0] > threshold) or (1 in counts and counts[1] > threshold):\n",
        "            biased_columns.append(column)\n",
        "    return biased_columns\n",
        "\n",
        "# trainとtestの両方で偏りのある列を探す\n",
        "biased_columns_train = find_biased_columns(train, threshold)\n",
        "biased_columns_test = find_biased_columns(test, threshold)\n",
        "biased_columns = list(set(biased_columns_train) | set(biased_columns_test))\n",
        "\n",
        "# 偏りのある列を削除\n",
        "train = train.drop(columns=biased_columns)\n",
        "test = test.drop(columns=biased_columns)\n"
      ],
      "metadata": {
        "id": "CA5IyAw4Kabg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "metadata": {
        "id": "lW3LYODXQFIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fDLs4R2AJMYO"
      },
      "outputs": [],
      "source": [
        "# ブール型データを数値型に変換\n",
        "train = train.applymap(lambda x: int(x) if isinstance(x, bool) else x)\n",
        "test = test.applymap(lambda x: int(x) if isinstance(x, bool) else x)\n",
        "# EXT_SOURCE_1 列が欠損値の行を抽出\n",
        "train_missing_ext_source_1 = train[train['EXT_SOURCE_3'].isna()]\n",
        "\n",
        "# EXT_SOURCE_1 列が埋めてある行を抽出\n",
        "train_filled_ext_source_1 = train[~train['EXT_SOURCE_3'].isna()]\n",
        "# EXT_SOURCE_1 列が欠損値の行を抽出\n",
        "test_missing_ext_source_1 = test[test['EXT_SOURCE_3'].isna()]\n",
        "\n",
        "# EXT_SOURCE_1 列が埋めてある行を抽出\n",
        "test_filled_ext_source_1 = test[~test['EXT_SOURCE_3'].isna()]\n",
        "# 埋めてある行を結合\n",
        "filled_ext_source_1 = pd.concat([train_filled_ext_source_1, test_filled_ext_source_1], ignore_index=True)\n",
        "# 残したい列のリスト\n",
        "columns_to_keep = ['DAYS_BIRTH', 'EXT_SOURCE_3','EXT_SOURCE_1']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "exp1 = setup(data = filled_ext_source_1, target = 'EXT_SOURCE_3', session_id=123,ignore_features = 'TARGET',  use_gpu=True, pca_components=0.95,feature_selection=True, feature_selection_method='univariate') #前処理を実行\n",
        "\n",
        "model = create_model('lightgbm')\n",
        "#パラメータチューニング\n",
        "final_model = finalize_model(model) #モデルの確定\n",
        "train_missing_ext_source_1 = train_missing_ext_source_1.drop(['EXT_SOURCE_3'], axis=1)\n",
        "result1 = predict_model(final_model, train_missing_ext_source_1)\n",
        "# 予測された値を元のデータフレームに埋め込む\n",
        "train.loc[train['EXT_SOURCE_3'].isna(), 'EXT_SOURCE_3'] = result1['prediction_label']\n",
        "test_missing_ext_source_1 = test_missing_ext_source_1.drop(['EXT_SOURCE_3'], axis=1)\n",
        "result2 = predict_model(final_model, test_missing_ext_source_1)\n",
        "test.loc[test['EXT_SOURCE_3'].isna(), 'EXT_SOURCE_3'] = result2['prediction_label']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYMVppJ9Jt5r"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YRDmhCdf_kE3"
      },
      "outputs": [],
      "source": [
        "# EXT_SOURCE_1 列が欠損値の行を抽出\n",
        "train_missing_ext_source_1 = train[train['EXT_SOURCE_1'].isna()]\n",
        "\n",
        "# EXT_SOURCE_1 列が埋めてある行を抽出\n",
        "train_filled_ext_source_1 = train[~train['EXT_SOURCE_1'].isna()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BnY5jyuN_njV"
      },
      "outputs": [],
      "source": [
        "# EXT_SOURCE_1 列が欠損値の行を抽出\n",
        "test_missing_ext_source_1 = test[test['EXT_SOURCE_1'].isna()]\n",
        "\n",
        "# EXT_SOURCE_1 列が埋めてある行を抽出\n",
        "test_filled_ext_source_1 = test[~test['EXT_SOURCE_1'].isna()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UkY5EbV__qta"
      },
      "outputs": [],
      "source": [
        "# 埋めてある行を結合\n",
        "filled_ext_source_1 = pd.concat([train_filled_ext_source_1, test_filled_ext_source_1], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ITt7oNVuBXzr"
      },
      "outputs": [],
      "source": [
        "# 残したい列のリスト\n",
        "columns_to_keep = ['DAYS_BIRTH', 'DAYS_EMPLOYED', 'EXT_SOURCE_2', 'EXT_SOURCE_3','EXT_SOURCE_1','FLAG_OWN_CAR','CODE_GENDER',]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eR25nOBo8sZN"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pycaret.classification import setup, compare_models, blend_models, tune_model, evaluate_model, finalize_model\n",
        "from pycaret.regression import *\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZST0p4XBq5d"
      },
      "outputs": [],
      "source": [
        "filled_ext_source_1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uj6DDNsf89rU"
      },
      "outputs": [],
      "source": [
        "exp1 = setup(data = filled_ext_source_1, target = 'EXT_SOURCE_1', session_id=45,ignore_features = 'TARGET',  use_gpu=True, pca_components=0.95,feature_selection=True, feature_selection_method='univariate') #前処理を実行"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27lR9dgD-o98"
      },
      "outputs": [],
      "source": [
        "model = create_model('lightgbm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVIjwzSg_Lb_"
      },
      "outputs": [],
      "source": [
        "final_model = finalize_model(model) #モデルの確定"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8v0oMjvoF2zz"
      },
      "outputs": [],
      "source": [
        "train_missing_ext_source_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fcFBcApfFBRk"
      },
      "outputs": [],
      "source": [
        "train_missing_ext_source_1 = train_missing_ext_source_1.drop(['EXT_SOURCE_1'], axis=1)\n",
        "result1 = predict_model(final_model, train_missing_ext_source_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iIGvxtpSIQMc"
      },
      "outputs": [],
      "source": [
        "# 予測された値を元のデータフレームに埋め込む\n",
        "train.loc[train['EXT_SOURCE_1'].isna(), 'EXT_SOURCE_1'] = result1['prediction_label']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8YBbcDKBHwO-"
      },
      "outputs": [],
      "source": [
        "test_missing_ext_source_1 = test_missing_ext_source_1.drop(['EXT_SOURCE_1'], axis=1)\n",
        "result2 = predict_model(final_model, test_missing_ext_source_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzQLM4sCIcHC"
      },
      "outputs": [],
      "source": [
        "test.loc[test['EXT_SOURCE_1'].isna(), 'EXT_SOURCE_1'] = result2['prediction_label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3a5wjybnFmy"
      },
      "outputs": [],
      "source": [
        "test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wm1qADlKpK0z"
      },
      "outputs": [],
      "source": [
        "test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2BEyWChSpP4h"
      },
      "outputs": [],
      "source": [
        "test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFHeWJsDcoDr"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 各列の中央値を計算\n",
        "median_ext_source_1_train = train['EXT_SOURCE_1'].median()\n",
        "median_ext_source_2_train = train['EXT_SOURCE_2'].median()\n",
        "median_ext_source_3_train = train['EXT_SOURCE_3'].median()\n",
        "\n",
        "median_ext_source_1_test = test['EXT_SOURCE_1'].median()\n",
        "median_ext_source_2_test = test['EXT_SOURCE_2'].median()\n",
        "median_ext_source_3_test = test['EXT_SOURCE_3'].median()\n",
        "\n",
        "# 条件を設定し、新しい列 'EXT_SOURCE_FLAG' を作成\n",
        "train['EXT_SOURCE_FLAG1'] = ((train['EXT_SOURCE_1'] <= median_ext_source_1_train) &\n",
        "                            (train['EXT_SOURCE_2'] <= median_ext_source_2_train) &\n",
        "                            (train['EXT_SOURCE_3'] <= median_ext_source_3_train)).astype(int)\n",
        "\n",
        "test['EXT_SOURCE_FLAG1'] = ((test['EXT_SOURCE_1'] <= median_ext_source_1_test) &\n",
        "                           (test['EXT_SOURCE_2'] <= median_ext_source_2_test) &\n",
        "                           (test['EXT_SOURCE_3'] <= median_ext_source_3_test)).astype(int)\n",
        "\n",
        "# 各列のパーセンタイル値を計算\n",
        "quantile_ext_source_1_train = train['EXT_SOURCE_1'].quantile(0.2)\n",
        "quantile_ext_source_2_train = train['EXT_SOURCE_2'].quantile(1/3)\n",
        "quantile_ext_source_3_train = train['EXT_SOURCE_3'].quantile(0.2)\n",
        "\n",
        "quantile_ext_source_1_test = test['EXT_SOURCE_1'].quantile(0.2)\n",
        "quantile_ext_source_2_test = test['EXT_SOURCE_2'].quantile(1/3)\n",
        "quantile_ext_source_3_test = test['EXT_SOURCE_3'].quantile(0.2)\n",
        "\n",
        "# 条件を設定し、新しい列 'EXT_SOURCE_FLAG' を作成\n",
        "train['EXT_SOURCE_FLAG2'] = ((train['EXT_SOURCE_1'] <= quantile_ext_source_1_train) &\n",
        "                            (train['EXT_SOURCE_2'] <= quantile_ext_source_2_train) &\n",
        "                            (train['EXT_SOURCE_3'] <= quantile_ext_source_3_train)).astype(int)\n",
        "\n",
        "test['EXT_SOURCE_FLAG2'] = ((test['EXT_SOURCE_1'] <= quantile_ext_source_1_test) &\n",
        "                           (test['EXT_SOURCE_2'] <= quantile_ext_source_2_test) &\n",
        "                           (test['EXT_SOURCE_3'] <= quantile_ext_source_3_test)).astype(int)\n",
        "\n",
        "\n",
        "# 各列の3分位点を計算\n",
        "quantile_ext_source_1_train = train['EXT_SOURCE_1'].quantile(1/3)\n",
        "quantile_ext_source_2_train = train['EXT_SOURCE_2'].quantile(1/3)\n",
        "quantile_ext_source_3_train = train['EXT_SOURCE_3'].quantile(1/3)\n",
        "\n",
        "quantile_ext_source_1_test = test['EXT_SOURCE_1'].quantile(1/3)\n",
        "quantile_ext_source_2_test = test['EXT_SOURCE_2'].quantile(1/3)\n",
        "quantile_ext_source_3_test = test['EXT_SOURCE_3'].quantile(1/3)\n",
        "\n",
        "# 条件を設定し、新しい列 'EXT_SOURCE_FLAG' を作成\n",
        "train['EXT_SOURCE_FLA3'] = ((train['EXT_SOURCE_1'] <= quantile_ext_source_1_train) &\n",
        "                            (train['EXT_SOURCE_2'] <= quantile_ext_source_2_train) &\n",
        "                            (train['EXT_SOURCE_3'] <= quantile_ext_source_3_train)).astype(int)\n",
        "\n",
        "test['EXT_SOURCE_FLAG3'] = ((test['EXT_SOURCE_1'] <= quantile_ext_source_1_test) &\n",
        "                           (test['EXT_SOURCE_2'] <= quantile_ext_source_2_test) &\n",
        "                           (test['EXT_SOURCE_3'] <= quantile_ext_source_3_test)).astype(int)\n",
        "\n",
        "# 各列の10分位点を計算\n",
        "quantile_ext_source_1_train = train['EXT_SOURCE_1'].quantile(0.1)\n",
        "quantile_ext_source_2_train = train['EXT_SOURCE_2'].quantile(0.1)\n",
        "quantile_ext_source_3_train = train['EXT_SOURCE_3'].quantile(0.1)\n",
        "\n",
        "quantile_ext_source_1_test = test['EXT_SOURCE_1'].quantile(0.1)\n",
        "quantile_ext_source_2_test = test['EXT_SOURCE_2'].quantile(0.1)\n",
        "quantile_ext_source_3_test = test['EXT_SOURCE_3'].quantile(0.1)\n",
        "\n",
        "# 条件を設定し、新しい列 'EXT_SOURCE_FLAG' を作成\n",
        "train['EXT_SOURCE_FLAG4'] = ((train['EXT_SOURCE_1'] <= quantile_ext_source_1_train) &\n",
        "                            (train['EXT_SOURCE_2'] <= quantile_ext_source_2_train) &\n",
        "                            (train['EXT_SOURCE_3'] <= quantile_ext_source_3_train)).astype(int)\n",
        "\n",
        "test['EXT_SOURCE_FLAG4'] = ((test['EXT_SOURCE_1'] <= quantile_ext_source_1_test) &\n",
        "                           (test['EXT_SOURCE_2'] <= quantile_ext_source_2_test) &\n",
        "                           (test['EXT_SOURCE_3'] <= quantile_ext_source_3_test)).astype(int)\n",
        "\n",
        "\n",
        "# Eoncodeしたい列をリストで指定。もちろん複数指定可能。\n",
        "list_cols = ['NAME_INCOME_TYPE','NAME_FAMILY_STATUS','REGION_RATING_CLIENT','REGION_RATING_CLIENT_W_CITY','CODE_GENDER','NAME_CONTRACT_TYPE','DEF_30_CNT_SOCIAL_CIRCLE','DEF_60_CNT_SOCIAL_CIRCLE',]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ZCExAaSFGkk"
      },
      "outputs": [],
      "source": [
        "train.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4IL84J-CnmI"
      },
      "outputs": [],
      "source": [
        "# trainデータの確認\n",
        "# 全体を表示するための設定変更\n",
        "\n",
        "print(f\"train shape: {train.shape}\")\n",
        "train.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ns__iaZ3CnmI"
      },
      "outputs": [],
      "source": [
        "# testデータの確認\n",
        "print(f\"test shape: {test.shape}\")\n",
        "test.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0BVWRTNhJgR"
      },
      "outputs": [],
      "source": [
        "# TARGET列を除いたtrainデータの特徴量部分を抽出\n",
        "train_features = train.drop(columns=['TARGET'])\n",
        "\n",
        "# 列名の確認\n",
        "train_columns = train_features.columns\n",
        "test_columns = test.columns\n",
        "\n",
        "print(\"Train Data Columns (without TARGET):\")\n",
        "print(train_columns)\n",
        "print(\"\\nTest Data Columns:\")\n",
        "print(test_columns)\n",
        "\n",
        "# 一致しているかどうかを確認\n",
        "if set(train_columns) == set(test_columns):\n",
        "    print(\"\\nThe column names match.\")\n",
        "else:\n",
        "    print(\"\\nThe column names do not match.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twSxP5kCgcq4"
      },
      "outputs": [],
      "source": [
        "print(test.columns)\n",
        "print(train.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dSQsnR71PlDN"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pycaret.classification import setup, compare_models,  create_model\n",
        "from pycaret.regression import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBBr2u_qU9MC"
      },
      "outputs": [],
      "source": [
        "train = train.drop(columns=['SK_ID_CURR'])\n",
        "test = test.drop(columns=['SK_ID_CURR'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08b_VXaRNAGV"
      },
      "outputs": [],
      "source": [
        "exp1 = setup(data=train,imputation_type= 'iterative', target='TARGET', session_id=123, ignore_features=[], use_gpu=True,pca_components=0.95)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_0cM5baSfDd"
      },
      "outputs": [],
      "source": [
        "final_model = finalize_model(model) #モデルの確定"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 列名の変更\n",
        "test.rename(columns={'EXT_SOURCE_FLAG3': 'EXT_SOURCE_FLA3'}, inplace=True)"
      ],
      "metadata": {
        "id": "FrThYoFUmG_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DGa16QimSiZd"
      },
      "outputs": [],
      "source": [
        "result1 = predict_model(final_model, test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cxaHrbzWleDX"
      },
      "outputs": [],
      "source": [
        "result1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c13Ycte5W047"
      },
      "outputs": [],
      "source": [
        "# 予測結果を提出用のフォーマットに格納\n",
        "sample_sub['TARGET'] = last_column\n",
        "# TARGET列のマイナス値を0に変換\n",
        "sample_sub['TARGET'] = sample_sub['TARGET'].apply(lambda x: 0 if x < 0 else x)\n",
        "sample_sub.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1を超える値があるかどうかを確認\n",
        "has_values_greater_than_one = (sample_sub['TARGET'] > 1).any()\n",
        "\n",
        "# 結果の表示\n",
        "if has_values_greater_than_one:\n",
        "    print(\"TARGET列には1を超える値が含まれています。\")\n",
        "else:\n",
        "    print(\"TARGET列には1を超える値は含まれていません。\")"
      ],
      "metadata": {
        "id": "pWWDhCa0myAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 0以下の値の数を確認\n",
        "num_values_less_or_equal_zero = (sample_sub['TARGET'] <= 0).sum()\n",
        "\n",
        "# 結果の表示\n",
        "print(f\"TARGET列には0以下の値が {num_values_less_or_equal_zero} 個含まれています。\")\n"
      ],
      "metadata": {
        "id": "Xyfil5EPm8cR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvvLh7-eW7ll"
      },
      "outputs": [],
      "source": [
        "# 提出用のcsvファイルを作成\n",
        "sample_sub.to_csv('submission.csv',index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEIQ6tJFYSs4"
      },
      "source": [
        "以上で、Home Credit Default Riskコンペのチュートリアルは終了です。今回は、50種類ある特徴量のうち5種類しか使用していないので、まだまだ改善の余地があります。この後は、このnotebookやこれまでの教材を参考にして、さらなるスコアの向上を目指してください！"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "interpreter": {
      "hash": "3fc12855e5119aa7119eb8b28b2c79e4453dd0444ad04c81a8c18197ce5b843e"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}